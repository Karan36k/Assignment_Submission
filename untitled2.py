# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1scWwKbdj7gcw_MNGNl2Tzqpj0wKqafuT

CODE FILE BY: KARAN ARORA (M22aie235)

The following github account is my account where the code file implementation will be saved

https://github.com/Karan36k/Assignment_Submission

CODE ANSWER TO QUESTION NUMBER 1

Question 1: Perceptron [30 points] 
1. In how many steps the perception learning algorithm will converge. 
2. What will be the final decision boundary? Show step-wise-step update of weight vector using computation as well as hand-drawn plot.
"""

import numpy as np
given_value = np.array([[1,1],[-1,-1],[0,0.5],[0.1,0.5],[0.2,0.2],[0.9,0.5]]) #this array is given in the question paper
y=[1,-1,-1,-1,1,1]
op_value = 0
w = [1,1] # As mentioned in the question we are initializing the weights as [1,1]
w = np.append(w,1) #appending our weight of 0 to 1
print(w)
print("conversion start...")
steps = 0
while (op_value != len(given_value)):
  steps = steps +1
  for value_taken_for_ref in range(len(given_value)):
    x = np.append(given_value[value_taken_for_ref,0:2],1)
    if y[value_taken_for_ref]==1: 
      if np.dot(np.transpose(w),x)>=0: 
        op_value=op_value+1
      else: #orange is classified as apple
        w=w+x
    else: #value_taken_for_ref is Negative (apple)
      if np.dot(np.transpose(w),x)<0: 
        op_value=op_value+1
      else: 
        w=w-x
  if(op_value != len(given_value)):
    op_value=0
print("convergence steps: "+ str(steps-1))
print(w)

"""CODE ANSWER TO QUESTION NUMBER 2

Problem 2: Learning to implement Neural Network [30 points] 
1. Gurmukhi Handwritten Digit Classification: Gurmukhi is one of the popular Indian scripts widely used in the Indian state of Punjab. In this part of the assignment, our goal is to develop a neural network solution (a simple NN, not a CNN) for classifying Gurmukhi digits. We provide you Handwritten Gurmukhi digit dataset here: 
1
Dataset link 
Modify the code provided in here and a video tutorial here, and develop a robust neural network to classify the Gurmukhi digits. Higher performance on the test set will have bonus points. Briefly write your observation and submit your code so that we can evaluate your implementation at our end. (10 points) 

"""

import numpy as np
import tensorflow as tf 
import matplotlib.pyplot as plt

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import datasets, layers, models

# I am now running this cell to download the dataset which is saved in my repository 

# to download dataset
!wget  -q https://github.com/karan36k/assignment_submission/raw/master/gurumukhi_digits_dataset/train.zip
!wget  -q https://github.com/karan36k/assignment_submission/raw/master/gurumukhi_digits_dataset/val.zip


# to unzip dataset 
!unzip -q train.zip -d gurumukhi_digits_dataset/
!unzip -q val.zip -d gurumukhi_digits_dataset/

def plot_loss_accuracy(history):
    '''
    A function to plot train and validation loss against epochs of training
    '''
    acc = history.history['accuracy']
    val_acc = history.history['val_accuracy']

    loss = history.history['loss']
    val_loss = history.history['val_loss']

    plt.figure(figsize=(8, 8))
    plt.subplot(2, 1, 1)
    plt.plot(acc, label='Training Accuracy')
    plt.plot(val_acc, label='Validation Accuracy')
    plt.legend(loc='lower right')
    plt.ylabel('Accuracy')
    plt.ylim([min(plt.ylim()),1])
    plt.title('Training and Validation Accuracy')

    plt.subplot(2, 1, 2)
    plt.plot(loss, label='Training Loss')
    plt.plot(val_loss, label='Validation Loss')
    plt.legend(loc='upper right')
    plt.ylabel('Cross Entropy')
    plt.ylim([0,2.0])
    plt.title('Training and Validation Loss')
    plt.xlabel('epoch')
    plt.show()

# using ImageDataGenerator to load data from the disk
# TODO : try if inverting white and black in dataset images has any effect on the performance of the model

train_data_path = 'gurumukhi_digits_dataset/train'
val_data_path = 'gurumukhi_digits_dataset/val'

IMAGE_SIZE = 32
IMAGE_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 1) # 3 channels
NUM_OF_CLASSES = 10

train_image_generator = ImageDataGenerator( rescale=1./255 )
val_image_generator = ImageDataGenerator( rescale=1./255 )

train_data_gen = train_image_generator.flow_from_directory(
    train_data_path, 
    target_size=(IMAGE_SIZE, IMAGE_SIZE), 
    color_mode='grayscale', # for 1 channel images
    class_mode='sparse', # labels will be integers
    batch_size=32, 
    shuffle=True, 
    seed=None,
    )

val_data_gen = val_image_generator.flow_from_directory(
    val_data_path, 
    target_size=(IMAGE_SIZE, IMAGE_SIZE), 
    color_mode='grayscale', # for 1 channel images
    class_mode='sparse', # labels will be integers
    batch_size=32, 
    shuffle=True, 
    seed=None,
    )

# checking/ validating some images generated by datagenerator

# This function will plot 4 images along with their labels.
def plotImages(image_datas,y_list):
    f, axarr = plt.subplots(2,2)
    axarr[0,0].imshow(image_datas[0], cmap='gray')
    axarr[0,0].set_title(y_list[0])
    axarr[0,0].axis('off')
    axarr[0,1].imshow(image_datas[1], cmap='gray')
    axarr[0,1].set_title(y_list[1])
    axarr[0,1].axis('off')
    axarr[1,0].imshow(image_datas[2], cmap='gray')
    axarr[1,0].set_title(y_list[2])
    axarr[1,0].axis('off')
    axarr[1,1].imshow(image_datas[3], cmap='gray')
    axarr[1,1].set_title(y_list[3])
    axarr[1,1].axis('off')

sample_training_images, y_list = next(train_data_gen)
sample_training_images = np.squeeze(sample_training_images) # to reduce dimension
print("shape of a batch given by image data generator : {}".format(sample_training_images.shape))

plotImages(sample_training_images[:4],y_list[:4])

# Trying a simple 1 layer NN : to get a baseline 
# TODO : make some variables to define learning rate, optimizer, etc. 

def create_1_layer_NN():
    model = tf.keras.models.Sequential([
        layers.Flatten(input_shape = IMAGE_SHAPE),
        layers.Dense(NUM_OF_CLASSES, activation='softmax') 
    ])

    model.compile(optimizer='adam',
                loss='sparse_categorical_crossentropy',
                metrics=['accuracy'])

    return model

one_layer_NN_model = create_1_layer_NN()
one_layer_NN_model.summary()

# training

one_layer_NN_checkpoint_filepath = 'one_layer_NN/checkpoint/'
one_layer_NN_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
    filepath=one_layer_NN_checkpoint_filepath,
    save_weights_only=True,
    monitor='val_accuracy',
    mode='max',
    save_best_only=True)

one_layer_NN_model_history = one_layer_NN_model.fit(train_data_gen, epochs=30, 
                    validation_data=val_data_gen,
                    callbacks=[one_layer_NN_checkpoint_callback])

plot_loss_accuracy(one_layer_NN_model_history)

"""Observations with 1 layer NN (i.e. no hidden layer)
Training accuracy reaches 100%
validation accuracy reaches 95%
Clear overfitting : with training accuracy reaching 100% while validation accuracy hovers around 94%
"""

# checking the model with saved weights by evaluating on validation data
one_layer_NN_checkpoint_filepath = 'one_layer_NN/checkpoint/'

one_layer_NN_model.load_weights(one_layer_NN_checkpoint_filepath)
one_layer_NN_model.evaluate(val_data_gen)

"""We can improve this"""

# Trying NN with 1 hidden layer

def create_1_hidden_layer_NN():
    model = tf.keras.models.Sequential([
        layers.Flatten(input_shape = IMAGE_SHAPE),
        layers.Dense(128, activation='relu'),
        layers.Dense(NUM_OF_CLASSES, activation='softmax') 
    ])

    model.compile(optimizer='adam',
                loss='sparse_categorical_crossentropy',
                metrics=['accuracy'])

    return model

one_hidden_layer_NN = create_1_hidden_layer_NN()
one_hidden_layer_NN.summary()

# training

one_hidden_layer_NN_checkpoint_filepath = 'one_hidden_layer_NN/checkpoint/'
one_hidden_layer_NN_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
    filepath=one_hidden_layer_NN_checkpoint_filepath,
    save_weights_only=True,
    monitor='val_accuracy',
    mode='max',
    save_best_only=True)

one_hidden_layer_NN_history = one_hidden_layer_NN.fit(train_data_gen, epochs=50, 
                    validation_data=val_data_gen,
                    callbacks=[one_hidden_layer_NN_checkpoint_callback])

one_hidden_layer_NN_checkpoint_filepath = 'one_hidden_layer_NN/checkpoint/'

one_hidden_layer_NN.load_weights(one_hidden_layer_NN_checkpoint_filepath)
one_hidden_layer_NN.evaluate(val_data_gen)

"""We can make this yet even more better"""

# now trying NN with multiple hidden layers

def create_multi_hidden_layer_NN():
    model = tf.keras.models.Sequential([
        layers.Flatten(input_shape = IMAGE_SHAPE),
        layers.Dense(64, activation='relu'),
        layers.Dense(32, activation='relu'),
        layers.Dense(NUM_OF_CLASSES, activation='softmax') 
    ])

    model.compile(optimizer='adam',
                loss='sparse_categorical_crossentropy',
                metrics=['accuracy'])

    return model

multi_hidden_layer_NN = create_multi_hidden_layer_NN()
multi_hidden_layer_NN.summary()

# training

multi_hidden_layer_NN_checkpoint_filepath = 'multi_hidden_layer_NN/checkpoint/'
multi_hidden_layer_NN_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
    filepath=multi_hidden_layer_NN_checkpoint_filepath,
    save_weights_only=True,
    monitor='val_accuracy',
    mode='max',
    save_best_only=True)

multi_hidden_layer_NN_checkpoint_filepath_history = multi_hidden_layer_NN.fit(train_data_gen, epochs=50, 
                    validation_data=val_data_gen,
                    callbacks=[multi_hidden_layer_NN_checkpoint_callback])

plot_loss_accuracy(multi_hidden_layer_NN_checkpoint_filepath_history)

"""Problem 3: Chart Image Classification using CNN [40 points] 
Problem statement: You have to develop a CNN-based classification architecture for clas sifying a given chart image to one of five chart classes, namely “Line”,“Dot Line”,“Horizontal Bar”,“Vertical Bar”, and “Pie” chart. 
Task 1: Download the dataset from drive link given below. 
Dataset link 
Use the train and val images for training and validation in an appropriate ratio (e.g., 80% for training and 20 % for validating). The CSV file contains corresponding labels for the images. 

"""

# importing the libraries
import pandas as pd
import numpy as np

# for reading and displaying images
from skimage.io import imread
import matplotlib.pyplot as plt
from sklearn import preprocessing 

# for creating validation set
from sklearn.model_selection import train_test_split

# for evaluating the model
from sklearn.metrics import accuracy_score
from tqdm import tqdm

# PyTorch libraries and modules
import torch
from torch.autograd import Variable
from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, BatchNorm2d
from torch.optim import Adam


# loading dataset
train = pd.read_csv('Chart/train_val.csv')
test = pd.read_csv('Chart/test.csv')

sample_submission = pd.read_csv('Chart/prediction.csv')

train.head()

# loading training images
train_img = []
for img_name in tqdm(train['image_index']):
    # defining the image path
    image_path = 'Chart/train_val/' + str(img_name) + '.png'
    # reading the image
    img = imread(image_path, as_gray=True)
    # normalizing the pixel values
    img /= 255.0
    # converting the type of pixel to float 32
    img = img.astype('float32')
    # appending the image into the list
    train_img.append(img)

# converting the list to numpy array
train_x = np.array(train_img)
# defining the target
train_y = train['type'].values
train_x.shape

# create validation set
train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size = 0.2)
(train_x.shape, train_y.shape), (val_x.shape, val_y.shape)

encoder = preprocessing.LabelEncoder()

# converting training images into torch format
train_x = train_x.reshape(800, 1, 128, 128)
train_x  = torch.from_numpy(train_x)

# converting the target into torch format
train_y = encoder.fit_transform(train_y)

train_y = train_y.astype(int);
train_y = torch.from_numpy(train_y)

# shape of training data
train_x.shape, train_y.shape

# converting validation images into torch format
val_x = val_x.reshape(200, 1, 128, 128)
val_x  = torch.from_numpy(val_x)

# converting the target into torch format
val_y = encoder.fit_transform(val_y)

val_y = val_y.astype(int);
val_y = torch.from_numpy(val_y)

# shape of validation data
val_x.shape, val_y.shape

class Net(Module):   
    def __init__(self):
        super(Net, self).__init__()

        self.cnn_layers = Sequential(
            # Defining a 2D convolution layer
            Conv2d(1, 4, kernel_size=3, stride=1, padding=1),
            BatchNorm2d(4),
            ReLU(inplace=True),
            MaxPool2d(kernel_size=2, stride=2),
            # Defining another 2D convolution layer
            Conv2d(4, 4, kernel_size=3, stride=1, padding=1),
            BatchNorm2d(4),
            ReLU(inplace=True),
            MaxPool2d(kernel_size=2, stride=2),
        )

        self.linear_layers = Sequential(
            Linear(4 * 32 * 32, 10)
        )

    # Defining the forward pass    
    def forward(self, x):
        x = self.cnn_layers(x)
        x = x.view(x.size(0), -1)
        x = self.linear_layers(x)
        return x

# defining the model
model = Net()
# defining the optimizer
optimizer = Adam(model.parameters(), lr=0.07)
# defining the loss function
criterion = CrossEntropyLoss()
# checking if GPU is available
if torch.cuda.is_available():
    model = model.cuda()
    criterion = criterion.cuda()

def train(epoch):
    model.train()
    tr_loss = 0
    # getting the training set
    x_train, y_train = Variable(train_x), Variable(train_y)

    y_train = y_train.long()

    # getting the validation set
    x_val, y_val = Variable(val_x), Variable(val_y)
    y_val = y_val.long()
    # converting the data into GPU format
    if torch.cuda.is_available():
        x_train = x_train.cuda()
        y_train = y_train.cuda()
        x_val = x_val.cuda()
        y_val = y_val.cuda()

    # clearing the Gradients of the model parameters
    optimizer.zero_grad()
    
    # prediction for training and validation set
    output_train = model(x_train)
    output_val = model(x_val)

    # computing the training and validation loss
    loss_train = criterion(output_train, y_train)
    loss_val = criterion(output_val, y_val)
    train_losses.append(loss_train)
    val_losses.append(loss_val)

    # computing the updated weights of all the model parameters
    loss_train.backward()
    optimizer.step()

# defining the number of epochs
n_epochs = 50
# empty list to store training losses
train_losses = []
# empty list to store validation losses
val_losses = []
# training the model
for epoch in range(n_epochs):
    train(epoch)

# plotting the training and validation loss
with torch.no_grad():    
    plt.plot(train_losses, label='Training loss')
    plt.plot(val_losses, label='Validation loss')
    plt.legend()
    plt.show()

# prediction for training set
with torch.no_grad():
    output = model(train_x)
    
softmax = torch.exp(output).cpu()
prob = list(softmax.numpy())
predictions = np.argmax(prob, axis=1)

# accuracy on training set
accuracy_score(train_y, predictions)

# prediction for validation set
with torch.no_grad():
    output = model(val_x)

softmax = torch.exp(output).cpu()
prob = list(softmax.numpy())
predictions = np.argmax(prob, axis=1)

# accuracy on validation set
accuracy_score(val_y, predictions)

# loading test images
test_img = []
for img_name in tqdm(test['image_index']):
    # defining the image path
    image_path = 'Chart/test/' + str(img_name) + '.png'
    # reading the image
    img = imread(image_path, as_gray=True)
    # normalizing the pixel values
    img /= 255.0
    # converting the type of pixel to float 32
    img = img.astype('float32')
    # appending the image into the list
    test_img.append(img)

# converting the list to numpy array
test_x = np.array(test_img)
test_x.shape

# converting training images into torch format
test_x = test_x.reshape(50, 1, 128, 128)
test_x  = torch.from_numpy(test_x)
test_x.shape

# generating predictions for test set
with torch.no_grad():
    output = model(test_x)

softmax = torch.exp(output).cpu()
prob = list(softmax.numpy())
predictions = np.argmax(prob, axis=1)

predictions = encoder.inverse_transform(predictions)

# replacing the label with prediction
sample_submission['type'] = predictions
sample_submission.head()

# saving the file
sample_submission.to_csv('Chart/prediction.csv', index=False)